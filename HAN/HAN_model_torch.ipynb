{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab44fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2023.01.12，复现HAN(Heterogeneous Graph Attention Network)\\ndependencies:\\n    torch-1.10.0\\n    numpy-1.22.0\\n    networkx-2.8.8\\n    scipy-1.7.3\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2023.01.12，复现HAN(Heterogeneous Graph Attention Network)\n",
    "dependencies:\n",
    "    torch-1.10.0\n",
    "    numpy-1.22.0\n",
    "    networkx-2.8.8\n",
    "    scipy-1.7.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e658ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import os\n",
    "project_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f381c583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN Algorithms\\\\HAN'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d591e",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c5a16",
   "metadata": {},
   "source": [
    "## data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f8e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd1767",
   "metadata": {},
   "source": [
    "### adj_to_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c5e1857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Prepare adjacency matrix by expanding up to a given neighbourhood.\\n This will insert loops on every node.\\n Finally, the matrix is converted to bias vectors.\\n Expected shape: [graph, nodes, nodes]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Prepare adjacency matrix by expanding up to a given neighbourhood.\n",
    " This will insert loops on every node.\n",
    " Finally, the matrix is converted to bias vectors.\n",
    " Expected shape: [graph, nodes, nodes]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81cc0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 邻接矩阵转换为偏置矩阵\n",
    "def adj_to_bias(adj, sizes, nhood=1): # 邻接矩阵adjacency matrix,(1,3025,3025)\n",
    "    num_graphs = adj.shape[0]  # 一个graph，一个邻接矩阵，返回邻接矩阵number\n",
    "    matrix = np.empty(adj.shape)  # 根据给定的维度和数值类型，numpy创建一个新的ndarray数组，其元素不进行初始化\n",
    "    for g in range(num_graphs):  # 第几个graph\n",
    "        matrix[g] = np.eye(adj.shape[1])  # 返回一个单位矩阵，一个对角线为1的ndarray数组\n",
    "        for n in range(nhood):\n",
    "            matrix[g] = np.matmul(matrix[g], (adj[g]+np.eye(adj.shape[1]))) # graph邻接矩阵+单位阵，再乘单位阵\n",
    "        # 判断每个graph 邻接矩阵元素的数值\n",
    "        for i in range(sizes[g]):\n",
    "            for j in range(sizes[g]):\n",
    "                if matrix[g][i][j] > 0.0:\n",
    "                    matrix[g][i][j] = 1.0\n",
    "    return -1e9 * (1.0 - matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f82b79",
   "metadata": {},
   "source": [
    "### loading_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d47b0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "def loading_file(filename):\n",
    "    \"parse index file.\"\n",
    "    file = []\n",
    "    for line in open(filename):\n",
    "        file.append(int(file.strip()))\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1db37f",
   "metadata": {},
   "source": [
    "### sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f32e08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成掩码bool数组\n",
    "def sample_mask(index, l):\n",
    "    \"create mask\"\n",
    "    mask = np.zeros(l)  # 生成全是0的数组\n",
    "    mask[index] = 1\n",
    "    return np.array(mask, dtype=np.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5b095",
   "metadata": {},
   "source": [
    "### sparse_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8a61d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取函数\n",
    "def extract_elements(mx):\n",
    "    if not sp.isspmatrix_coo(mx):\n",
    "        mx = mx.tocoo()  # 转换成coo稀疏矩阵\n",
    "    coo_index = np.vstack((mx.row, mx.col)).transpose()  # row和col是index array；vstack按行上下拼接\n",
    "    values = mx.data\n",
    "    shape = mx.shape\n",
    "    return coo_index, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "853b1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取sparse稀疏矩阵元素\n",
    "def sparse_elements(sparse_mx):\n",
    "    \"convert sparse matrix to tuple representation\"\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = extract_elements(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = extract_elements(sparse_mx)\n",
    "    \n",
    "    return sparse_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa318c5b",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34806fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1dc28",
   "metadata": {},
   "source": [
    "### attn_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b1553a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_head(features, out_sz, bias_mat, activation, in_drop=0.0, coef_drop=0.0, residual=False, \n",
    "              return_coef=False):\n",
    "    if in_drop != 0.0:\n",
    "        features = F.dropout(features, p=1-in_drop )\n",
    "    features_conv1d = F.conv1d(features, weight=out_sz, stride=1, bias=False)\n",
    "    \n",
    "    f_1 = F.conv1d(features_conv1d, 1, 1)\n",
    "    f_2 = F.conv1d(features_conv1d, 1, 1)\n",
    "    \n",
    "    logits = f_1 + torch.permute(f_2, (0,2,1)) # 转置\n",
    "    coefs = F.softmax(nn.LeakyReLU(logits) + bias_mat)\n",
    "    \n",
    "    if coef_drop != 0.0:\n",
    "        coefs = F.dropout(coefs, p=1-coef_drop)\n",
    "    if in_drop != 0.0:\n",
    "        features_conv1d = F.dropout(features_conv1d, p=1-in_drop)\n",
    "    \n",
    "    vals = torch.matmul(coefs, features_conv1d)\n",
    "    ret = torch.add(vals, bias)\n",
    "    \n",
    "    # residual connection 残差连接\n",
    "    if residual:\n",
    "        if features.shape[-1] != ret.shape[-1]:\n",
    "            ret = ret + F.conv1d(features, ret.shape[-1], 1)  # activation\n",
    "        else:\n",
    "            features_conv1d = ret + features\n",
    "    if return_coef:\n",
    "        return activation(ret), coefs\n",
    "    else:\n",
    "        return activation(ret)  # activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520c512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
